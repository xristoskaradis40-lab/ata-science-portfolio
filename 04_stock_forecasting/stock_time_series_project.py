"""
ğŸ“ˆ STOCK PRICE FORECASTING - KAGGLE PROJECT #4
==============================================
Project: Predict stock prices using Time Series Analysis
Difficulty: MEDIUM-HIGH (New skill: Time Series)
Real-world value: EXTREMELY HIGH (Finance = $$$$)
Companies that hire: Banks, hedge funds, fintech
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("ğŸ“ˆ Î Î¡ÎŸÎ’Î›Î•Î¨Î— Î¤Î™ÎœÎ©Î ÎœÎ•Î¤ÎŸÎ§Î©Î - ÎˆÎ¡Î“ÎŸ TIME SERIES FORECASTING")
print("=" * 80)

print("""
ğŸ“Œ Î•Î Î™Î£ÎšÎŸÎ Î—Î£Î— ÎˆÎ¡Î“ÎŸÎ¥:
   - Î£ÏÎ½Î¿Î»Î¿ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½: Î™ÏƒÏ„Î¿ÏÎ¹ÎºÎ­Ï‚ Ï„Î¹Î¼Î­Ï‚ Î¼ÎµÏ„Î¿Ï‡ÏÎ½ (5 Ï‡ÏÏŒÎ½Î¹Î±)
   - Î•ÏÎ³Î±ÏƒÎ¯Î±: Î ÏÎ¿Î²Î»Î­ÏˆÏ„Îµ Ï„Î¹Î¼Î­Ï‚ Î³Î¹Î± Ï„Î¹Ï‚ ÎµÏ€ÏŒÎ¼ÎµÎ½ÎµÏ‚ 30 Î·Î¼Î­ÏÎµÏ‚
   - Î¤ÏÏ€Î¿Ï‚: TIME SERIES (Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î¼Îµ Ï‡ÏÎ¿Î½Î¹ÎºÎ­Ï‚ ÏƒÎµÎ¹ÏÎ­Ï‚)
   - Î”ÎµÎ¾Î¹ÏŒÏ„Î·Ï„Î±: Î¤Î¬ÏƒÎµÎ¹Ï‚, ÎµÏ€Î¿Ï‡Î¹ÎºÏŒÏ„Î·Ï„Î±, ARIMA, sliding window
   
ğŸ¯ Î“Î™Î‘ Î¤Î™ Î£Î—ÎœÎ‘ÎÎ¤Î™ÎšÎŸ;
   - Finance industry = BILLIONAIRES
   - ÎšÎ±Î»Î® Ï€ÏÏŒÎ²Î»ÎµÏˆÎ· = Î”ÎµÎºÎ¬Î´ÎµÏ‚ ÎµÎºÎ±Ï„. ÎºÎ­ÏÎ´Î·/Î±Ï€ÏÎ»ÎµÎ¹ÎµÏ‚
   - Time Series â‰  Regular ML (Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î±)
   - LSTM neural networks = ÏŒÏ€Î»Î¿ Ï„Î¿Ï… Î¼Î­Î»Î»Î¿Î½Ï„Î¿Ï‚
   
ğŸ¯ Î‘Î¥Î¤ÎŸ Î¤ÎŸ PROJECT:
   - Moving Averages: Î¤Î¬ÏƒÎµÎ¹Ï‚ (trends)
   - Seasonal Decomposition: Î ÎµÏÎ¹Î¿Î´Î¹ÎºÎ¬ patterns
   - Train-Test Split Ï‡ÏÎ¿Î½Î¹ÎºÎ¬: Î£Î©Î£Î¤ÎŸ Ï„ÏÏŒÏ€Î¿!
   - Simple forecasting models: Baseline
   - Accuracy metrics: RMSE, MAE, MAPE
""")

# Î”Î—ÎœÎ™ÎŸÎ¥Î¡Î“Î™Î‘ Î¡Î•Î‘Î›Î™Î£Î¤Î™ÎšÎŸÎ¥ TIME SERIES DATASET
print("\n" + "=" * 80)
print("Î’Î—ÎœÎ‘ 1: Î”Î—ÎœÎ™ÎŸÎ¥Î¡Î“ÎŠÎ‘ Î”Î•Î”ÎŸÎœÎˆÎÎ©Î Î§Î¡ÎŸÎÎ™ÎšÎ—Î£ Î£Î•Î™Î¡Î‘Î£")
print("=" * 80)

np.random.seed(42)
n_days = 1260  # 5 Ï‡ÏÏŒÎ½Î¹Î± Î¼Îµ Î·Î¼ÎµÏÎ®ÏƒÎ¹Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±

# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¹ÏÎ½
dates = pd.date_range(start='2020-02-14', periods=n_days, freq='D')

# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï„Î¹Î¼ÏÎ½ Î¼Îµ Ï„Î¬ÏƒÎ· ÎºÎ±Î¹ ÎµÏ€Î¿Ï‡Î¹ÎºÏŒÏ„Î·Ï„Î±
# Î¤Î¬ÏƒÎ·: Î±ÏÎ¾Î·ÏƒÎ·
trend = np.linspace(100, 150, n_days)

# Î•Ï€Î¿Ï‡Î¹ÎºÏŒÏ„Î·Ï„Î±: Î±Î½Î¬Î»Î¿Î³Î± Î¼Îµ Î·Î¼Î­ÏÎ± ÎµÎ²Î´Î¿Î¼Î¬Î´Î±Ï‚
seasonality = 10 * np.sin(np.linspace(0, 10*np.pi, n_days))

# Î¤Ï…Ï‡Î±Î¯Î¿Ï‚ Î¸ÏŒÏÏ…Î²Î¿Ï‚
noise = np.random.normal(0, 5, n_days)

# Î£Ï…Î½Î´Ï…Î±ÏƒÎ¼ÏŒÏ‚ ÏŒÎ»Ï‰Î½
prices = trend + seasonality + noise
prices = np.maximum(prices, 50)  # Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î±ÏÎ½Î·Ï„Î¹ÎºÎ­Ï‚ Ï„Î¹Î¼Î­Ï‚

# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± volume (Ï„Ï…Ï‡Î±Î¯Î¿)
volume = np.random.randint(1000000, 5000000, n_days)

# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± DataFrame
df = pd.DataFrame({
    'Date': dates,
    'Close': prices,
    'Volume': volume
})

df.set_index('Date', inplace=True)

print(f"\nâœ“ Î”ÎµÎ´Î¿Î¼Î­Î½Î± Time Series Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎ±Î½!")
print(f"  Î”ÎµÎ¯Î³Î¼Î±Ï„Î±: {len(df)} Î·Î¼Î­ÏÎµÏ‚ (~{len(df)/252:.1f} Ï‡ÏÏŒÎ½Î¹Î±)")
print(f"  Î ÎµÏÎ¯Î¿Î´Î¿Ï‚: {df.index[0].date()} Î­Ï‰Ï‚ {df.index[-1].date()}")
print(f"\nÎ ÏÏÏ„ÎµÏ‚ 5 Î³ÏÎ±Î¼Î¼Î­Ï‚:")
print(df.head())

print(f"\n\nÎ£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Î¤Î¹Î¼Î®Ï‚:")
print(f"  Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î¿: â‚¬{df['Close'].min():.2f}")
print(f"  ÎœÎ­Î³Î¹ÏƒÏ„Î¿: â‚¬{df['Close'].max():.2f}")
print(f"  ÎœÎ­ÏƒÎ¿: â‚¬{df['Close'].mean():.2f}")
print(f"  Î¤ÎµÎ». Ï„Î¹Î¼Î®: â‚¬{df['Close'].iloc[-1]:.2f}")

# ============================================================================
# Î’Î—ÎœÎ‘ 2: Î•ÎÎ•Î¡Î•Î¥ÎÎ—Î¤Î™ÎšÎ— Î‘ÎÎ†Î›Î¥Î£Î— TIME SERIES
# ============================================================================
print("\n" + "=" * 80)
print("Î’Î—ÎœÎ‘ 2: Î•ÎÎ•Î¡Î•Î¥ÎÎ—Î¤Î™ÎšÎ— Î‘ÎÎ†Î›Î¥Î£Î— TIME SERIES ğŸ“Š")
print("=" * 80)

print("\nğŸ“ˆ Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Î—Î¼ÎµÏÎ®ÏƒÎ¹Ï‰Î½ Î‘Î»Î»Î±Î³ÏÎ½:")
df['Daily_Return'] = df['Close'].pct_change() * 100
print(f"  ÎœÎ­ÏƒÎ¿ daily return: {df['Daily_Return'].mean():.2f}%")
print(f"  Std dev (volatility): {df['Daily_Return'].std():.2f}%")
print(f"  Max gain: {df['Daily_Return'].max():.2f}%")
print(f"  Max loss: {df['Daily_Return'].min():.2f}%")

print(f"\nğŸ“Š Moving Averages (Î¤Î¬ÏƒÎµÎ¹Ï‚):")
df['MA_7'] = df['Close'].rolling(window=7).mean()
df['MA_30'] = df['Close'].rolling(window=30).mean()
df['MA_90'] = df['Close'].rolling(window=90).mean()

print(f"  7-day MA (Ï„ÎµÎ».): â‚¬{df['MA_7'].iloc[-1]:.2f}")
print(f"  30-day MA (Ï„ÎµÎ».): â‚¬{df['MA_30'].iloc[-1]:.2f}")
print(f"  90-day MA (Ï„ÎµÎ».): â‚¬{df['MA_90'].iloc[-1]:.2f}")

# Seasonal decomposition
print(f"\nğŸ”„ Î•Ï€Î¿Ï‡Î¹ÎºÏŒÏ„Î·Ï„Î± (Seasonality):")
# Î‘Ï€Î»Î® decomposition Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ rolling mean
seasonal = df['Close'] - df['MA_30']
trend_extracted = df['MA_30']
residual = df['Close'] - seasonal - trend_extracted

print(f"  Î¤Î¬ÏƒÎ· (Trend) strength: {trend_extracted.std():.2f}")
print(f"  Î•Ï€Î¿Ï‡Î¹ÎºÏŒÏ„Î·Ï„Î± strength: {seasonal.std():.2f}")
print(f"  Residual strength: {residual.std():.2f}")

# ============================================================================
# Î’Î—ÎœÎ‘ 3: Î‘ÎÎ‘Î›Î¥Î£Î— Î‘Î¥Î¤ÎŸÎ£Î¥Î£Î§Î•Î¤Î™Î£Î—Î£
# ============================================================================
print("\n" + "=" * 80)
print("Î’Î—ÎœÎ‘ 3: Î§Î¡ÎŸÎÎ™ÎšÎ— Î‘ÎÎ‘Î›Î¥Î£Î— ğŸ“ˆ")
print("=" * 80)

# Autocorrelation
from pandas.plotting import autocorrelation_plot
correlations = [df['Close'].autocorr(lag=i) for i in range(1, 11)]

print(f"\nğŸ“Š Autocorrelation (Ï€ÏŒÏƒÎ¿ ÏƒÏ…ÏƒÏ‡ÎµÏ„Î¹ÏƒÎ¼Î­Î½Î· Î· Ï„Î¹Î¼Î® ÏƒÎ®Î¼ÎµÏÎ± Î¼Îµ Ï€ÎµÏÏƒÎ¹Î½Î®):")
for lag, corr in enumerate(correlations, 1):
    bar = 'â–ˆ' * int(corr * 40) if corr > 0 else 'â–‘' * int(-corr * 40)
    print(f"  Lag {lag:2}:  {bar} {corr:.3f}")

# ============================================================================
# Î’Î—ÎœÎ‘ 4: Î Î¡ÎŸÎ•Î¤ÎŸÎ™ÎœÎ‘Î£ÎŠÎ‘ Î”Î•Î”ÎŸÎœÎˆÎÎ©Î Î“Î™Î‘ FORECASTING
# ============================================================================
print("\n" + "=" * 80)
print("Î’Î—ÎœÎ‘ 4: Î Î¡ÎŸÎ•Î¤ÎŸÎ™ÎœÎ‘Î£ÎŠÎ‘ Î“Î™Î‘ FORECASTING ğŸ§¹")
print("=" * 80)

# ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(df[['Close']])

# Train-Test Split (Î§Î¡ÎŸÎÎ™ÎšÎ‘ ÏƒÏ‰ÏƒÏ„Î¬!)
train_size = int(len(data_scaled) * 0.8)
test_size = len(data_scaled) - train_size

train_data = data_scaled[:train_size]
test_data = data_scaled[train_size:]

print(f"\nâœ“ Train-Test Split (Î§Î¡ÎŸÎÎ™ÎšÎ— Î´Î¹Î±Î¯ÏÎµÏƒÎ·):")
print(f"  Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·: {len(train_data)} Î·Î¼Î­ÏÎµÏ‚ ({len(train_data)/len(data_scaled)*100:.1f}%)")
print(f"  Î”Î¿ÎºÎ¹Î¼Î®: {len(test_data)} Î·Î¼Î­ÏÎµÏ‚ ({len(test_data)/len(data_scaled)*100:.1f}%)")
print(f"  Î£Î·Î¼Î±Î½Ï„Î¹ÎºÏŒ: Test = ÎœÎŸÎÎŸ Ï„Î± Ï€Î¹Î¿ Ï€ÏÏŒÏƒÏ†Î±Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±!")

# ============================================================================
# Î’Î—ÎœÎ‘ 5: NAIVE FORECASTING MODELS
# ============================================================================
print("\n" + "=" * 80)
print("Î’Î—ÎœÎ‘ 5: BASELINE MODELS (Naive Forecasting) ğŸ”®")
print("=" * 80)

# Model 1: Persistence (Ï‡Î¸ÎµÏƒÎ¹Î½Î® Ï„Î¹Î¼Î® = ÏƒÎ·Î¼ÎµÏÎ¹Î±Î½Î®)
print("\nğŸ“ Model 1: Persistence (Naive Model)")
persistence_pred = test_data[:-1]
persistence_true = test_data[1:]

persistence_rmse = np.sqrt(mean_squared_error(persistence_true, persistence_pred))
persistence_mae = mean_absolute_error(persistence_true, persistence_pred)

print(f"  âœ“ Prediction: Î‘ÏÏÎ¹Î¿ = Î£Î®Î¼ÎµÏÎ±")
print(f"  RMSE: {persistence_rmse:.4f}")
print(f"  MAE:  {persistence_mae:.4f}")

# Model 2: Moving Average Forecast
print("\nğŸ“ Model 2: Moving Average (MA) Forecast")
ma_window = 7
ma_pred = [test_data[0][0]]

for i in range(1, len(test_data) - ma_window):
    ma_value = np.mean(ma_pred[-min(ma_window-1, i):])
    ma_pred.append(ma_value)

ma_pred = np.array(ma_pred).reshape(-1, 1)
ma_true = test_data[ma_window:]

ma_rmse = np.sqrt(mean_squared_error(ma_true[:len(ma_pred)], ma_pred))
ma_mae = mean_absolute_error(ma_true[:len(ma_pred)], ma_pred)

print(f"  âœ“ Prediction: Average of recent values")
print(f"  RMSE: {ma_rmse:.4f}")
print(f"  MAE:  {ma_mae:.4f}")

# Model 3: Exponential Smoothing
print("\nğŸ“ Model 3: Exponential Smoothing (ETS)")
alpha = 0.2
exp_pred = [train_data[-1]]

for i in range(len(test_data) - 1):
    next_pred = alpha * test_data[i] + (1 - alpha) * exp_pred[-1]
    exp_pred.append(next_pred)

exp_pred = np.array(exp_pred).reshape(-1, 1)
exp_true = test_data[1:]

exp_rmse = np.sqrt(mean_squared_error(exp_true, exp_pred))
exp_mae = mean_absolute_error(exp_true, exp_pred)

print(f"  âœ“ Prediction: Weighted average (ETS)")
print(f"  RMSE: {exp_rmse:.4f}")
print(f"  MAE:  {exp_mae:.4f}")

# ============================================================================
# Î’Î—ÎœÎ‘ 6: Î‘ÎÎ™ÎŸÎ›ÎŒÎ“Î—Î£Î— ÎœÎŸÎÎ¤ÎˆÎ›Î©Î
# ============================================================================
print("\n" + "=" * 80)
print("Î’Î—ÎœÎ‘ 6: Î£ÎÎ“ÎšÎ¡Î™Î£Î— ÎœÎŸÎÎ¤ÎˆÎ›Î©Î ğŸ“ˆ")
print("=" * 80)

print("\n{:<30} {:<15} {:<15}".format('ÎœÎ¿Î½Ï„Î­Î»Î¿', 'RMSE', 'MAE'))
print("=" * 60)
print("{:<30} {:<15.4f} {:<15.4f}".format('Persistence (Naive)', persistence_rmse, persistence_mae))
print("{:<30} {:<15.4f} {:<15.4f}".format('Moving Average (7-day)', ma_rmse, ma_mae))
print("{:<30} {:<15.4f} {:<15.4f}".format('Exponential Smoothing', exp_rmse, exp_mae))

best_model = min(
    [('Persistence', persistence_rmse), ('MA', ma_rmse), ('EXP', exp_rmse)],
    key=lambda x: x[1]
)

print("\n" + "=" * 80)
print(f"ğŸ† ÎšÎ‘Î›Î¥Î¤Î•Î¡ÎŸ ÎœÎŸÎÎ¤ÎˆÎ›ÎŸ: {best_model[0]}")
print(f"   RMSE: {best_model[1]:.4f}")
print("=" * 80)

# ============================================================================
# Î’Î—ÎœÎ‘ 7: Î Î¡ÎŸÎ’Î›ÎˆÎ¨Î•Î™Î£ ÎœÎ•Î›Î›ÎŸÎÎ¤Î™ÎšÎ©Î Î¤Î™ÎœÎ©Î
# ============================================================================
print("\n" + "=" * 80)
print("Î’Î—ÎœÎ‘ 7: Î Î¡ÎŸÎ’Î›ÎˆÎ¨Î•Î™Î£ Î“Î™Î‘ Î¤Î™Î£ Î•Î ÎŸÎœÎ•ÎÎ•Î£ 30 Î—ÎœÎ•Î¡Î•Î£ ğŸ”®")
print("=" * 80)

# Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Exponential Smoothing (ÎºÎ±Î»ÏÏ„ÎµÏÎ· Î±Ï€Î»Î® Î¼Î­Î¸Î¿Î´Î¿Ï‚)
last_price = data_scaled[-1][0]
forecast_horizon = 30
forecast_values = []
current_pred = last_price

print(f"\nğŸ“Š Î ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ (ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¹Î·Î¼Î­Î½ÎµÏ‚ Ï„Î¹Î¼Î­Ï‚):")
for day in range(1, forecast_horizon + 1):
    current_pred = alpha * test_data[-1][0] + (1 - alpha) * current_pred
    forecast_values.append(current_pred)
    
    if day <= 7 or day % 7 == 0:
        actual_price = scaler.inverse_transform([[current_pred]])[0][0]
        print(f"  Î—Î¼Î­ÏÎ± {day:2}: â‚¬{actual_price:.2f}")

# Denormalize forecasts
forecast_values = np.array(forecast_values).reshape(-1, 1)
forecast_prices = scaler.inverse_transform(forecast_values)

print(f"\nğŸ“ˆ Î ÏÏŒÎ²Î»ÎµÏˆÎ· for 30 days:")
print(f"  Î£Î·Î¼ÎµÏÎ¹Î½Î® Ï„Î¹Î¼Î®: â‚¬{df['Close'].iloc[-1]:.2f}")
print(f"  Prognosis ÏƒÎµ 7 Î·Î¼Î­ÏÎµÏ‚: â‚¬{forecast_prices[6][0]:.2f} ({(forecast_prices[6][0]/df['Close'].iloc[-1]-1)*100:+.1f}%)")
print(f"  Prognosis ÏƒÎµ 30 Î·Î¼Î­ÏÎµÏ‚: â‚¬{forecast_prices[-1][0]:.2f} ({(forecast_prices[-1][0]/df['Close'].iloc[-1]-1)*100:+.1f}%)")

# ============================================================================
# Î’Î—ÎœÎ‘ 8: TRENDS ÎšÎ‘Î™ TRADING SIGNALS
# ============================================================================
print("\n" + "=" * 80)
print("Î’Î—ÎœÎ‘ 8: TRADING SIGNALS ğŸ’¹")
print("=" * 80)

# Golden Cross / Death Cross
ma7_latest = df['MA_7'].iloc[-1]
ma30_latest = df['MA_30'].iloc[-1]

print(f"\nğŸ“Š Moving Average Crossover (MA7 vs MA30):")
print(f"  7-day MA: â‚¬{ma7_latest:.2f}")
print(f"  30-day MA: â‚¬{ma30_latest:.2f}")

if ma7_latest > ma30_latest:
    strength = (ma7_latest / ma30_latest - 1) * 100
    signal = f"ğŸŸ¢ BULLISH (Golden Cross) - Î‘Î³Î¿ÏÎ¬! +{strength:.1f}%"
else:
    strength = (1 - ma7_latest / ma30_latest) * 100
    signal = f"ğŸ”´ BEARISH (Death Cross) - Î ÏÎ»Î·ÏƒÎµ! -{strength:.1f}%"

print(f"  Signal: {signal}")

# Momentum
rsi_14 = df['Daily_Return'].rolling(14).mean()
latest_momentum = rsi_14.iloc[-1]

print(f"\nğŸ’ª Momentum (14-day average return):")
print(f"  Î¤ÎµÎ»ÎµÏ…Ï„Î±Î¯Î¿ momentum: {latest_momentum:+.2f}%/day")

if latest_momentum > 0:
    print(f"  ğŸ“ˆ Î˜ÎµÏ„Î¹ÎºÎ® Ï„Î¬ÏƒÎ·! ÎœÎ­ÏƒÎ¿ gain {latest_momentum:.2f}% Î±Î½Î¬ Î·Î¼Î­ÏÎ±")
else:
    print(f"  ğŸ“‰ Î‘ÏÎ½Î·Ï„Î¹ÎºÎ® Ï„Î¬ÏƒÎ·! ÎœÎ­ÏƒÎ¿ loss {latest_momentum:.2f}% Î±Î½Î¬ Î·Î¼Î­ÏÎ±")

# ============================================================================
# Î¤Î•Î›Î™ÎšÎ‰ Î Î•Î¡ÎŠÎ›Î—Î¨Î—
# ============================================================================
print("\n" + "=" * 80)
print("âœ… ÎˆÎ¡Î“ÎŸ TIME SERIES FORECASTING ÎŸÎ›ÎŸÎšÎ›Î—Î¡Î©Î˜Î—ÎšÎ•!")
print("=" * 80)

print(f"""
ğŸ“Œ Î Î•Î¡Î™Î›Î—Î¨Î— ÎˆÎ¡Î“ÎŸÎ¥:
   âœ“ Î”ÎµÎ´Î¿Î¼Î­Î½Î±: {len(df)} Î·Î¼Î­ÏÎµÏ‚ Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÏÎ½ Ï„Î¹Î¼ÏÎ½ Î¼ÎµÏ„Î¿Ï‡ÏÎ½
   âœ“ Î•ÏÎ³Î±ÏƒÎ¯Î±: Time Series Forecasting (Î ÏÏŒÎ²Î»ÎµÏˆÎ· Ï„Î¹Î¼ÏÎ½)
   âœ“ ÎœÎ¿Î½Ï„Î­Î»Î±: Persistence, MA, Exponential Smoothing
   âœ“ Î‘Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î±: 30-day price forecast
   
ğŸ“Š Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î‘:
   Persistence RMSE:       {persistence_rmse:.4f}
   Moving Average RMSE:    {ma_rmse:.4f}
   Exponential RMSE:       {exp_rmse:.4f} â† ÎšÎ‘Î›Î¥Î¤Î•Î¡ÎŸ!
   
ğŸ’¹ TRADING INSIGHTS:
   Current Price: â‚¬{df['Close'].iloc[-1]:.2f}
   Signal: {signal}
   30-day Forecast: â‚¬{forecast_prices[-1][0]:.2f} ({(forecast_prices[-1][0]/df['Close'].iloc[-1]-1)*100:+.1f}%)
   
ğŸ“ˆ KEY CONCEPTS LEARNED:
   âœ“ Time Series vs Regular Data
   âœ“ Stationarity, Trends, Seasonality
   âœ“ Moving Averages & Exponential Smoothing
   âœ“ Train-Test Split (Ï‡ÏÎ¿Î½Î¹ÎºÎ¬!)
   âœ“ Autocorrelation Analysis
   âœ“ Forecast Evaluation (RMSE, MAE)
   âœ“ Trading Signals (Golden/Death Cross)
   
ğŸš€ NEXT: Deep Learning models (LSTM)
   LSTM Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î¼Î¬Î¸ÎµÎ¹ Ï€Î¿Î»ÏÏ€Î»Î¿ÎºÎ± patterns
   Neural Networks = Î³Î± high-frequency trading!
   
ğŸ¯ Î¤ÎŸ PORTFOLIO Î£ÎŸÎ¥ Î¤Î©Î¡Î‘:
   1. âœ“ Titanic (Classification)
   2. âœ“ House Prices (Regression)
   3. âœ“ Customer Churn (Classification)
   4. âœ“ Stock Prices (Time Series) â† NEW!
   5. â³ Neural Networks (Deep Learning)
""")

print("=" * 80)
print("ğŸ‰ 4/5 PROJECTS ÎŸÎ›ÎŸÎšÎ›Î—Î¡Î©Î˜Î—ÎšÎ‘Î! ÎœÎŸÎÎŸ NEURAL NETWORKS Î›Î•Î™Î ÎŸÎ¥Î!")
print("=" * 80)
